# 虚拟内存

物理内存是计算机实际可用的物理硬件，而虚拟内存则是由操作系统创建的抽象概念。

为每个程序设置一段”连续”的虚拟地址空间，把这个地址空间分割成多个具有连续地址范围的页 (page)，并把这些页和物理内存做映射，在程序运行期间动态映射到物理内存。当程序引用到一段在物理内存的地址空间时，由硬件立刻执行必要的映射；而当程序引用到一段不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令

通过虚拟内存，进程可以使用比物理内存更大的地址空间，并且不必关心物理内存的实际位置。这种抽象层次使得操作系统可以更好地管理内存，确保每个进程都能够访问其所需的内存

当程序中使用 malloc 等分配内存的接口时会将内存从待分配状态变成已分配状态，此时这块分配好的内存还没有真正映射到对应的物理内存上，这块内存就是未映射状态，因为它并没有被映射到相应的物理内存，直到对该块内存进行读写时，操作系统才会真正地为它分配物理内存。然后这个页面才能成为正常页面。

# 页目录PDE/页表PTE

在`x86`系统中，为了能够更加充分、灵活的使用物理内存，把物理内存按照`4KB`的单位进行分页。

然后通过中间的映射表，把连续的虚拟内存空间，映射到离散的物理内存空间。

映射表中的每一个表项，都指向一个物理页的开始地址。

但是这样的映射表有一个明显的缺点：映射表自身也是需保存在物理内存中的。

在 32 位系统中，它使用了多达`4MB`的物理内存空间(每个表项`4`个字节，一共有`4G/4K`个表项)。

为了解决这个问题，`x86`处理器使用了两级转换：页目录和页表。

```
页目录 -> 页目录项(指向页表的指针)
				 ······
				 页目录项 -> 页表 -> 页表项
													 ······ 
													 页表项(指向物理内存页面的指针)
```

页目录包含了若干个页目录项，每个页目录项又包含了一个指向页表的指针。

页表包含了若干个页表项，每个页表项又包含了一个指向物理内存中某个页面的指针

当进程需要访问内存时，它会使用虚拟地址进行寻址。操作系统会首先在页目录中查找对应的页目录项，然后使用这个页目录项指向的页表来确定虚拟地址对应的物理地址

## 缺页中断

在 **内存管理单元（Memory Management Unit，MMU）**进行地址转换时，如果页表项的 “在/不在” 位是 0，则表示该页面并没有映射到真实的物理页框，则会引发一个**缺页中断**，CPU 进入操作系统内核，接着操作系统就会通过页面置换算法选择一个页面将其换出 (swap)，以便为即将调入的新页面腾出位置，如果要换出的页面的页表项里的修改位已经被设置过，也就是被更新过，则这是一个**脏页** (dirty page)，需要写回磁盘更新改页面在磁盘上的副本，如果该页面是”干净”的，也就是没有被修改过，则直接用调入的新页面覆盖掉被换出的旧页面即可。

## TLB

**TLB（Translation Lookaside Buffer），每个core一个TLB，类似L1 cache**，也叫快表，是用来加速虚拟地址映射的

TLB 可以简单地理解成页表的高速缓存，保存了最高频被访问的页表项，由于一般是硬件实现的，因此速度极快，MMU 收到虚拟地址时一般会先通过硬件 TLB 查询对应的页表号，若命中且该页表项的访问操作合法，则直接从 TLB 取出对应的物理页框号返回，若不命中则穿透到内存页表里查询，并且会用这个从内存页表里查询到最新页表项替换到现有 TLB 里的其中一个，以备下次缓存命中。

# 内核内存管理

- 现在的内核中，内存管理最大概念为`node`。
- 在node上再分为一个或者几个`zone`
- 每个`zone`中又分为不同的迁移类型

在`linux`内核中，整个内存信息和状态的展示可以通过以下几个文件获得：

| 文件                 | 描述                                                        |
| -------------------- | ----------------------------------------------------------- |
| `/proc/buddyinfo`    | 展示系统上各个`zone`的`buddy`信息，主要用来分析内存碎片问题 |
| `/proc/pagetypeinfo` | 输出系统上各个`zone`中的不同迁移类型的详细状态信息          |
| `/proc/vmstat`       | 描述内存统计信息                                            |
| `/proc/zoneinfo`     | 输出系统上各个内存`zone`的详细信息                          |

## zone

- ZONE_DMA标记适合DMA的内存域，在IA-32计算机上，一般的现在是16MB，该区域供I/O设备直接访问，不需要通过MMU管理，连续分配，具有更高的性能。

- ZONE_DMA32，标记了使用32位地址可寻址、适合DMA的内存域，显然只有64位系统上，才会有该内存域。

- ZONE_NORMAL，可以直接映射到**内核段**的普通内存域，这是所有体系机构上保证都会存在的唯一内存域，在IA-32系统上，该域可访问的最大内存不超过896MiB，超过该值的内存只能能通过高端内存寻址访问ZONE_HIGHMEM中的内存。

- ZONE_HIGHMEM，超出了内核段的物理内存。只有在可用物理内存多余可映射的内核内存时，才会访问该域，显然一般只有32位系统上才会有可能有该区域。通过kmap及kunmap将该域内存映射到内核虚拟地址空间。

- ZONE_MOVEABLE，这个区域主要是给用户空间分配使用。

前三个zone主要为内核所用到，最后一个主要被用户空间用到，内核空间内存域具体划分见下图：

## buddy

又叫伙伴系统。伙伴系统负责各个zone物理内存的分配、释放。伙伴系统所分配的物理内存页全部都是**物理上连续的，并且只能分配 2 的整数幂个页**，这里的整数幂在内核中称之为分配阶 order。

在操作系统分配内存的过程中，一个内存块常常被分成两个大小相等的内存块，这两个大小相等的内存块就处于伙伴关系。它满足 3 个条件 ：

- 两个块具有相同大小记为 2^K
- 它们的物理地址是连续的
- 从同一个大块中拆分出来

比如阶 order = 1 的内存块，内存块中包含了两个连续的空闲 page。这两个空闲 page 就是伙伴

buddy系统承担zone里面物理内存的分配和释放

- 把内存按照页划分成很多阶，最大阶为MAX_ORDER，一般设置为11，每个阶内存区的内存块数为2^n，我们称之为**内存区**。

> 在我们调用物理内存分配接口时，均需要指定这个分配阶 order，意思是从伙伴系统申请多少个物理内存页，假设我们指定分配阶为 order，那么就会从伙伴系统中申请 2 的 order 次幂个物理内存页。
>
> 伙伴系统会将物理内存区域中的空闲内存根据分配阶 order 划分出不同尺寸的内存块，并将这些不同尺寸的内存块分别用一个双向链表组织起来。
>
> 比如：分配阶 order 为 0 时，对应的内存块就是一个 page。分配阶 order 为 1 时，对应的内存块就是 2 个 pages。依次类推，当分配阶 order 为 n 时，对应的内存块就是 2 的 order 次幂个 pages。

- 当进程申请一段内存时，总是从适合大小的阶中分配指定**内存区**，比如当分配7k(4k * 2^1，7k离8k最近)内存的时候，会从第1阶分配对应的**内存区**。
- 当第k个阶的**内存区**全部被分完，没有可分配的k阶内存区时，会从第K+1阶划分出来两个新的**内存区**，供第K阶使用。比如第4阶的内存内存都分配完了，从第5阶分裂出来两个四阶的内存区。
- 当从高阶内存区划分出来的两个区都被释放时，该两个区的两个内存区会重新合并回高阶内存区

# Page Cache

`read(2)/write(2)` 是 Linux 系统中最基本的 I/O 读写系统调用，而在这两个系统调用和真实的磁盘读写之间存在一层称为 `Kernel buffer cache` 的缓冲区缓存。在 Linux 中 I/O 缓存其实可以细分为两个：`Page Cache` 和 `Buffer Cache`，这两个其实是一体两面，共同组成了 Linux 的内核缓冲区（Kernel Buffer Cache），Page Cache 是在应用程序读写文件的过程中产生的：

- **读磁盘**：内核会先检查 `Page Cache` 里是不是已经缓存了这个数据，若是，直接从这个内存缓冲区里读取返回，若否，则穿透到磁盘去读取，然后再缓存在 `Page Cache` 里，以备下次缓存命中；
- **写磁盘**：内核直接把数据写入 `Page Cache`，并把对应的页标记为 dirty，添加到 dirty list 里，然后就直接返回，内核会定期把 dirty list 的页缓存 flush 到磁盘，保证页缓存和磁盘的最终一致性。

## pagecache产生和释放

- 标准 I/O 是写的 (write(2)) 用户缓冲区 (Userpace Page 对应的内存)，**然后再将用户缓冲区里的数据拷贝到内核缓冲区 (Pagecache Page 对应的内存)**；如果是读的 (read(2)) 话则是先从内核缓冲区拷贝到用户缓冲区，再从用户缓冲区读数据，也就是 buffer 和文件内容不存在任何映射关系。
- 对于存储映射 I/O（Memory-Mapped I/O） 而言，则是直接将 Pagecache Page 给映射到用户地址空间，用户直接读写 Pagecache Page 中内容，效率相对标准IO更高一些

当 **将用户缓冲区里的数据拷贝到内核缓冲区 (Pagecache Page 对应的内存)** 最容易发生**缺页中断**，OS需要先分配Page（应用感知到的就是卡顿了）

缺页后kswapd在短时间内回收不了足够多的 free 内存，或kswapd 还没有触发执行，操作系统就会进行内存页直接回收。这个过程中，应用会进行自旋等待直到回收的完成，从而产生巨大的延迟。

# 内存规整

伙伴系统是基于页来管理的内存的，内存碎片也是基于页的，即由大量离散且不连续的页面导致的。

**内存规整(memory compaction)**就是内核去内存碎片的机制

一个系统上，内存规整模块的运行信息，可以通过文件`/proc/vmstat`来查看，如下：

```bash
$ cat /proc/vmstat  | grep compact
compact_migrate_scanned 26654488
compact_free_scanned 857655344
compact_isolated 2530461
compact_stall 355
compact_fail 70
compact_success 285
```

- `compact_stall` 可以简单理解为系统进行内存规整的次数（不包括手动触发内存规整）
- `compact_fail` 表示内存规整失败的次数
- `compact_success` 表示内存规整成功的次数

## 时机

- **直接分配内存**：分配大块内存时(order > 1) ，在低水位情况下分配失败，唤醒kswapd线程后依然无法分配内存，这时调用`__alloc_pages_direct_compact`来进行内存规整，然后再尝试分配所需的内存。
- **手动触发**：手动写入`echo 1 > /proc/sys/vm/compact_memory`，会扫面系统中所有的内存节点上的zone，对每个zone都会做一次内存规整
- **kcompactd内核线程**：和页面回收kswapd内核线程一样，每个内存节点都会创建一个kcompactd内核线程，名称为"kcompactd0"，“kcompactd1"等

## 内存碎片化相关`extfag`文件

- 内存分配失败原因: `/sys/kernel/debug/extfrag/extfrag_index`

```bash
# cat extfrag_index
Node 0, zone      DMA -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000
Node 0, zone    DMA32 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.988 -1.000
Node 0, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000
Node 1, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000
```

该值有意义的是有前提的，只有内存预计内存分配将失败时，该值用来反映导致失败的原因，`0` 代表是由于内存不足导致，`1` 代表是由于内存碎片导致。

该值有特殊的值`-1`：表示内存分配不会失败

- 内存碎片化指数: `/sys/kernel/debug/extfrag/unusable_index`

```bash
# cat unusable_index
Node 0, zone      DMA 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.090 0.272
Node 0, zone    DMA32 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.001 0.004 0.011
Node 0, zone   Normal 0.000 0.002 0.006 0.027 0.038 0.043 0.047 0.076 0.132 0.324 0.324
Node 1, zone   Normal 0.000 0.000 0.000 0.006 0.010 0.013 0.021 0.041 0.076 0.149 0.159
```

该值表示一个`zone`中所有的空闲内存中，有多少是不能满足分配`order`大小的内存

该值的范围最小为`0`，最大为`1`

`0`代表没有内存碎片，表示所有的空闲内存都能满足内存分配，`1`代表内存碎片严重，表示所有的空闲内存都不能满足内存分配

